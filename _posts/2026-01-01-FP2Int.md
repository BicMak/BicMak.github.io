---
title: Float,Int 양자화 방법
date: 2026-01-01 20:30:00 +0900
categories: [Quantization]
tags: [Quantization, pytorch]
math: true
---


# 1. 양자화 준비

$$
q = \frac{1}{S}\cdot(r+Z)
$$

- 해당식에 보면 $S$는 스케일계수, $r$은 실수, $Z$는 영점으로 표현이 가능함
- 반대로 게산을 하면 실수를 아래와같이 양자화 스케일로 표현이 가능함

$$
r = {S}\cdot(q-Z)
$$

![alt text](/assets/img/2026-01-02-FP2Int/image.png)

# 2. 양자화된 행렬 곱셈


### 2.1. 양자화된 행렬 곱셈 (Quantized Matrix Multiplication)

---
행렬 곱 $\mathbf{Y = WX}$를 양자화된 도메인에서 계산하기 위한 수식 전개 과정

$$
S_Y (\mathbf{q_Y} - Z_Y) = S_W (\mathbf{q_W} - Z_W) \cdot S_X (\mathbf{q_X} - Z_X)
$$

- 이를 $\mathbf{q_Y}$에 대해 정리하고 전개하면 다음과 같습니다.

$$
\mathbf{q_Y} = \frac{S_W S_X}{S_Y} (\mathbf{q_W} - Z_W) (\mathbf{q_X} - Z_X) + Z_Y
$$

$$
\mathbf{q_Y} = \frac{S_W S_X}{S_Y} (\mathbf{q_W} \mathbf{q_X} - Z_W \mathbf{q_X} - Z_X \mathbf{q_W} + Z_W Z_X) + Z_Y
$$

- 해당 식에서 실제로 양자화 연산에서 필요한 값은 $\mathbf{q_W} \mathbf{q_X}$ 고 나머지 3항 $Z_W \mathbf{q_X} - Z_X \mathbf{q_W} + Z_W Z_X$ 은 노이즈로 작용하여 SQNR을 감소 시키는 요인이 됨

---

### 3. 하드웨어 최적화 트릭 (Fixed-point & Precompute)

그래서 수학적인 트릭을 사용해서 해당 노이즈 값을 제거 해주기 위한 방법이 필요함

- Multiplier ($M_{0}$) 근사 (이미지 1):
    
    $$
    \frac{S_W S_X}{S_Y} = 2^{-n} M_0, \quad M_0 \in [0.5, 1)
    $$
    
    (여기서 $2^{-n}$은 Bit Shift, $M_0$는 Fixed-point Multiplication으로 처리)
    
    곱셈을 bit shift 로 변경하여 불필요한 곱연산을 줄여줌
    
- $Z_W = 0$ 및 바이어스 통합 (이미지 4, 5):
    
    가중치의 영점$(Z_W)$이 0일 때 식은 다음과 같이 간소화됩니다.
    
    $$
    \mathbf{q_Y} = \frac{S_W S_X}{S_Y} (\mathbf{q_W} \mathbf{q_X} - Z_X \mathbf{q_W}) + Z_Y
    $$
    
    즉 가중치가 symetrical quantization이 됬다고 가정하면 노이즈가 줄어들게 됨→ 가중치의 영점값을 미리 반영해서 양자화할때 반영
    
- 바이어스 포함 최종 형태 (이미지 5):
    
    $$
    \mathbf{q_Y} = \frac{S_W S_X}{S_Y} (\mathbf{q_W} \mathbf{q_X} + \mathbf{q_{bias}}) + Z_Y
    $$
    
    $$
    \text{where } \mathbf{q_{bias}} = \mathbf{q_b} - Z_X \mathbf{q_W}
    $$
    
- 그렇게 하면 아래와 같이 $q_{bias}$로 noise 값이 줄어들기 때문에 실질적인 Qsnr을 개선 가능함

---

# 4. 부록: 부동소수점 연산이 정수형보다 느린 이유

근본적으로 느린이유는 CPU를 설계할때 ALU자체에서 FP연산을 어떻게 처리하는지 봐야 됨. 양자화를 하려고 하는 목적이 단순 용량을 줄이는것만 있는게 아니라 추론속도를 높이는 목적도 있음

$$
F1 = (-1)^{s_1} \cdot M_1 \cdot 2^{n_1} \\
F2 = (-1)^{s_2} \cdot M_2 \cdot 2^{n_2} \tag{1}
$$

- 식 1을 보면 F1,F2라는 2개의 정수형 변수가 있고 정수형을 표현하는 방법은 위와 같이 수식으로 나타낼 수 있음

## 4.1 덧셈

- 정수형 연산은 지수부 $n1,n2$ 가 서로 똑같을 때만 가능하기 때문에 n2에 n1과의 차이만큼 덧셈연산 진행

$$
n1 = n2 +shift \tag{2}

$$

- 이때 지수부의 숫자가 큰쪽을 기준으로 해서 작은수의 비트를 shift 해주는게 정확도 측면에서 유리함

$$
F1 + F2= [(-1)^{s_1} \cdot M_1 + (-1)^{s_2 } \cdot M_2 \cdot 2^{shift}  ]2^{n_2 + shift} \tag{3}
$$

- 그리고 위의 식을 풀어서 결과값을 구하게 되면 아래 와 같이 표현이 가능함 $M_{result}$ 에 부호연산이 포함 되어있다고 가정

$$
M_{result}\cdot 2^{result}=(-1)^{s_1} \cdot M_1 + (-1)^{s_2 } \cdot M_2 \cdot 2^{shift} \tag{4}
$$

$$
F1 + F2= [M_{result}\cdot 2^{result} ]2^{n_2 + shift} \tag{5}
$$

$$
F1 + F2= M_{result} \cdot 2^{n_2 + shift+result} \tag{6}
$$

## 4.2 곱셈

- 지수의 곱셈은 밑이 동일하다면 덧셈연산으로 표현이 가능하기 때문에 덧셈보다 연산이 간단함

$$
F1 = (-1)^{s_1} \cdot M_1 \cdot 2^{n_1}\\
F2 = (-1)^{s_2} \cdot M_2 \cdot 2^{n_2} \tag{7}
$$

- 최종 결과는 아래와 같다.

$$
F1 \cdot F2= (-1)^{s_1+s_2} \cdot M_1 M_2 \cdot 2^{n_1 + n_2} \tag{8}
$$

- 자세히 보면 각 개별 파라미터 s, M, n 에 마다 연산을 해주고 그걸 합치는 과정에서 필요한 연산이 많기 때문에 정수형 보다 느림

출처 : https://hanlab.mit.edu/courses/2024-fall-65940